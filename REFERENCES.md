## References
1. Araki, S., Ito, N., Haeb-Umbach, R., Wichern, G., Wang, Z. Q., & Mitsufuji, Y. (2025, April). 30+ years of source separation research: Achievements and future challenges. In ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1-5). IEEE.
2. Lu, W. T., Wang, J. C., Kong, Q., & Hung, Y. N. (2024, April). Music source separation with band-split rope transformer. In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 481-485). IEEE.
3. Mariani, G., Tallini, I., Postolache, E., Mancusi, M., Cosmo, L., & Rodolà, E. (2023). Multi-source diffusion models for simultaneous music generation and separation. arXiv preprint arXiv:2302.02257.
4. Fabbro, G., Uhlich, S., Lai, C. H., Choi, W., Martínez-Ramírez, M., Liao, W., ... & Mitsufuji, Y. (2023). The Sound Demixing Challenge 2023$\unicode {x2013} $ Music Demixing Track. arXiv preprint arXiv:2308.06979.
5. Sawata, R., Takahashi, N., Uhlich, S., Takahashi, S., & Mitsufuji, Y. (2024). The whole is greater than the sum of its parts: improving music source separation by bridging networks. EURASIP Journal on Audio, Speech, and Music Processing, 2024(1), 39.
6. Rouard, S., Massa, F., & Défossez, A. (2023, June). Hybrid transformers for music source separation. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1-5). IEEE.
7. Luo, Y., & Yu, J. (2023). Music source separation with band-split RNN. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 31, 1893-1901.
8. Plaja-Roglans, G., Miron, M., Shankar, A., & Serra, X. (2023). Carnatic singing voice separation using cold diffusion on training data with bleeding.
9. Pereira, I., Araújo, F., Korzeniowski, F., & Vogl, R. (2023). Moisesdb: A dataset for source separation beyond 4-stems. arXiv preprint arXiv:2307.15913.
10. Défossez, A. (2021). Hybrid spectrogram and waveform source separation. arXiv preprint arXiv:2111.03600.
11. Mitsufuji, Y., Fabbro, G., Uhlich, S., Stöter, F. R., Défossez, A., Kim, M., ... & Cheuk, K. W. (2022). Music demixing challenge 2021. Frontiers in Signal Processing, 1, 808395.
12. Kong, Q., Cao, Y., Liu, H., Choi, K., & Wang, Y. (2021). Decoupling magnitude and phase estimation with deep resunet for music source separation. arXiv preprint arXiv:2109.05418.
13. Subakan, C., Ravanelli, M., Cornell, S., Bronzi, M., & Zhong, J. (2021, June). Attention is all you need in speech separation. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 21-25). IEEE.
14. Hennequin, R., Khlif, A., Voituret, F., & Moussallam, M. (2020). Spleeter: a fast and efficient music source separation tool with pre-trained models. Journal of Open Source Software, 5(50), 2154.
15. Slizovskaia, O., Haro, G., & Gómez, E. (2021). Conditioned source separation for musical instrument performances. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 29, 2083-2095.
16. Wisdom, S., Tzinis, E., Erdogan, H., Weiss, R., Wilson, K., & Hershey, J. (2020). Unsupervised sound separation using mixture invariant training. Advances in neural information processing systems, 33, 3846-3857.
17. Hung, Y. N., & Lerch, A. (2020). Multitask learning for instrument activation aware music source separation. arXiv preprint arXiv:2008.00616.
18. Manilow, E., Seetharaman, P., & Pardo, B. (2020, May). Simultaneous separation and transcription of mixtures with multiple polyphonic and percussive instruments. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 771-775). IEEE.
19. Stöter, F. R., Uhlich, S., Liutkus, A., & Mitsufuji, Y. (2019). Open-unmix-a reference implementation for music source separation. Journal of Open Source Software, 4(41), 1667.
20. Meseguer-Brocal, G., & Peeters, G. (2019). Conditioned-U-Net: Introducing a control mechanism in the U-Net for multiple source separations. arXiv preprint arXiv:1907.01277.
21. Défossez, A., Usunier, N., Bottou, L., & Bach, F. (2019). Music source separation in the waveform domain. arXiv preprint arXiv:1911.13254.
22. Kavalerov, I., Wisdom, S., Erdogan, H., Patton, B., Wilson, K., Le Roux, J., & Hershey, J. R. (2019, October). Universal sound separation. In 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) (pp. 175-179). IEEE.
23. Manilow, E., Wichern, G., Seetharaman, P., & Le Roux, J. (2019, October). Cutting music source separation some Slakh: A dataset to study the impact of training data quality and quantity. In 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) (pp. 45-49). IEEE.
24. Luo, Y., & Mesgarani, N. (2019). Conv-tasnet: Surpassing ideal time–frequency magnitude masking for speech separation. IEEE/ACM transactions on audio, speech, and language processing, 27(8), 1256-1266.
25. Jansson, A., Bittner, R. M., Ewert, S., & Weyde, T. (2019, September). Joint singing voice separation and f0 estimation with deep u-net architectures. In 2019 27th European Signal Processing Conference (EUSIPCO) (pp. 1-5). IEEE.
26. Stoller, D., Ewert, S., & Dixon, S. (2018). Wave-u-net: A multi-scale neural network for end-to-end audio source separation. arXiv preprint arXiv:1806.03185.
27. Takahashi, N., Goswami, N., & Mitsufuji, Y. (2018, September). Mmdenselstm: An efficient combination of convolutional and recurrent neural networks for audio source separation. In 2018 16th International workshop on acoustic signal enhancement (IWAENC) (pp. 106-110). IEEE.
28. Rafii, Z., Liutkus, A., Stöter, F. R., Mimilakis, S. I., FitzGerald, D., & Pardo, B. (2018). An overview of lead and accompaniment separation in music. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 26(8), 1307-1335.
29. Cano, E., FitzGerald, D., Liutkus, A., Plumbley, M. D., & Stöter, F. R. (2018). Musical source separation: An introduction. IEEE Signal Processing Magazine, 36(1), 31-40.
30. Vincent, E., Virtanen, T., & Gannot, S. (Eds.). (2018). Audio source separation and speech enhancement. John Wiley & Sons.
31. Uhlich, S., Porcu, M., Giron, F., Enenkl, M., Kemp, T., Takahashi, N., & Mitsufuji, Y. (2017, March). Improving music source separation based on deep neural networks through data augmentation and network blending. In 2017 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 261-265). IEEE.
32. Chandna, P., Miron, M., Janer, J., & Gómez, E. (2017, February). Monoaural audio source separation using deep convolutional neural networks. In International conference on latent variable analysis and signal separation (pp. 258-266). Cham: Springer International Publishing.
33. Jansson, A., Humphrey, E., Montecchio, N., Bittner, R., Kumar, A., & Weyde, T. (2017). Singing voice separation with deep u-net convolutional networks.
34. Luo, Y., Chen, Z., Hershey, J. R., Le Roux, J., & Mesgarani, N. (2017, March). Deep clustering and conventional networks for music separation: Stronger together. In 2017 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 61-65). IEEE.
35. Rafii, Z., Liutkus, A., Stöter, F. R., Mimilakis, S. I., & Bittner, R. (2017). The MUSDB18 corpus for music separation.
36. Liutkus, A., Stöter, F. R., Rafii, Z., Kitamura, D., Rivet, B., Ito, N., ... & Fontecave, J. (2017, February). The 2016 signal separation evaluation campaign. In International conference on latent variable analysis and signal separation (pp. 323-332). Cham: Springer International Publishing.
37. Seetharaman, P., Pishdadian, F., & Pardo, B. (2017, October). Music/voice separation using the 2d fourier transform. In 2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) (pp. 36-40). IEEE.
38. Kitamura, D., Ono, N., Sawada, H., Kameoka, H., & Saruwatari, H. (2016). Determined blind source separation unifying independent vector analysis and nonnegative matrix factorization. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 24(9), 1626-1641.
39. Hershey, J. R., Chen, Z., Le Roux, J., & Watanabe, S. (2016, March). Deep clustering: Discriminative embeddings for segmentation and separation. In 2016 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 31-35). IEEE.
40. Ewert, S., Pardo, B., Muller, M., & Plumbley, M. D. (2014). Score-informed source separation for musical audio recordings: An overview. IEEE Signal Processing Magazine, 31(3), 116-124.
41. Grais, E. M., Sen, M. U., & Erdogan, H. (2014, May). Deep neural networks for single channel source separation. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 3734-3738). IEEE.
42. Huang, P. S., Kim, M., Hasegawa-Johnson, M., & Smaragdis, P. (2014, October). Singing-Voice Separation from Monaural Recordings using Deep Recurrent Neural Networks. In ISMIR (pp. 477-482).
43. Bittner, R. M., Salamon, J., Tierney, M., Mauch, M., Cannam, C., & Bello, J. P. (2014, October). Medleydb: A multitrack dataset for annotation-intensive mir research. In Ismir (Vol. 14, pp. 155-160).
44. Rafii, Z., & Pardo, B. (2012). Repeating pattern extraction technique (REPET): A simple method for music/voice separation. IEEE transactions on audio, speech, and language processing, 21(1), 73-84.
45. Vincent, E., Araki, S., Theis, F., Nolte, G., Bofill, P., Sawada, H., ... & Duong, N. Q. (2012). The signal separation evaluation campaign (2007–2010): Achievements and remaining challenges. Signal Processing, 92(8), 1928-1936.
46. Fitzgerald, D. (2010). Harmonic/percussive separation using median filtering.
47. Ozerov, A., & Févotte, C. (2009). Multichannel nonnegative matrix factorization in convolutive mixtures for audio source separation. IEEE transactions on audio, speech, and language processing, 18(3), 550-563.
48. Virtanen, T. (2007). Monaural sound source separation by nonnegative matrix factorization with temporal continuity and sparseness criteria. IEEE transactions on audio, speech, and language processing, 15(3), 1066-1074.
49. Vincent, E., Gribonval, R., & Févotte, C. (2006). Performance measurement in blind audio source separation. IEEE transactions on audio, speech, and language processing, 14(4), 1462-1469.
50. Yilmaz, O., & Rickard, S. (2004). Blind separation of speech mixtures via time-frequency masking. IEEE Transactions on signal processing, 52(7), 1830-1847.
51. Smaragdis, P., & Brown, J. C. (2003, October). Non-negative matrix factorization for polyphonic music transcription. In 2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (IEEE Cat. No. 03TH8684) (pp. 177-180). IEEE.
52. Plumbley, M. D., Abdallah, S. A., Bello, J. P., Davies, M. E., Monti, G., & Sandler, M. B. (2002). Automatic music transcription and audio source separation. Cybernetics &Systems, 33(6), 603-627.
53. Tunturi, E., Diaz-Guerra, D., Politis, A., & Virtanen, T. (2025). Score-informed Music Source Separation: Improving Synthetic-to-real Generalization in Classical Music. arXiv preprint arXiv:2503.07352.
54. Wu, J., Liu, J., Pan, T., Tang, J., & Wu, G. (2025). Towards Practical Real-Time Low-Latency Music Source Separation. arXiv preprint arXiv:2511.13146.
55. Défossez, A., Usunier, N., Bottou, L., & Bach, F. (2019). Demucs: Deep extractor for music sources with extra unlabeled data remixed. arXiv preprint arXiv:1909.01174.
56. Plaja-Roglans, G., Hung, Y. N., Serra, X., & Pereira, I. (2025). Efficient and fast generative-based singing voice separation using a latent diffusion model. arXiv preprint arXiv:2511.20470.
57. Zang, Y., Hai, J., Ge, W., Kong, Q., Dai, Z., Wang, H., ... & Plumbley, M. D. (2025). MSRBench: A Benchmarking Dataset for Music Source Restoration. arXiv preprint arXiv:2510.10995.
58. Tzinis, E., Wisdom, S., Hershey, J. R., Jansen, A., & Ellis, D. P. (2020, May). Improving universal sound separation using sound classification. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 96-100). IEEE.
59. Yang, J., Yang, Y., Tu, W., Zhao, X., & Lin, C. (2025). Band-SCNet: A Causal, Lightweight Model for High-Performance Real-Time Music Source Separation. In Proc. Interspeech 2025 (pp. 4973-4977).
60. Favaro, A., Lewis, A., & Schlesinger, G. ICA for Musical Signal Separation.
61. Vardhan, S., Acharya, P. R., Rao, S. S., Jasthi, O. R., & Natarajan, S. (2025, April). An Ensemble Approach to Music Source Separation: A Comparative Analysis of Conventional and Hierarchical Stem Separation. In International Conference on Computational Intelligence in Music, Sound, Art and Design (Part of EvoStar) (pp. 186-201). Cham: Springer Nature Switzerland.
62. Vincent, E. (2005). Musical source separation using time-frequency source priors. IEEE Transactions on Audio, Speech, and Language Processing, 14(1), 91-98.
63. Lluís, F., Pons, J., & Serra, X. (2018). End-to-end music source separation: Is it possible in the waveform domain?. arXiv preprint arXiv:1810.12187.
64. Schulze-Forster, K., Richard, G., Kelley, L., Doire, C. S., & Badeau, R. (2023). Unsupervised music source separation using differentiable parametric source models. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 31, 1276-1289.
65. Zhu, G., Darefsky, J., Jiang, F., Selitskiy, A., & Duan, Z. (2022). Music source separation with generative flow. IEEE Signal Processing Letters, 29, 2288-2292.
66. Lee, J. H., Choi, H. S., & Lee, K. (2019). Audio query-based music source separation. arXiv preprint arXiv:1908.06593. Jeon, C. B., Wichern, G., Germain, F. G., & Le Roux, J. (2024, April). Why does music source separation benefit from cacophony?. In 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW) (pp. 873-877). IEEE.
67. Liu, R., & Li, S. (2009, September). A review on music source separation. In 2009 IEEE Youth Conference on Information, Computing and Telecommunication (pp. 343-346). IEEE.
68. Uhlich, S., Porcu, M., Giron, F., Enenkl, M., Kemp, T., Takahashi, N., & Mitsufuji, Y. (2017, March). Improving music source separation based on deep neural networks through data augmentation and network blending. In 2017 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 261-265). IEEE.
69. Seetharaman, P., Wichern, G., Venkataramani, S., & Le Roux, J. (2019, May). Class-conditional embeddings for music source separation. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 301-305). IEEE.
70. Kadandale, V. S., Montesinos, J. F., Haro, G., & Gómez, E. (2020, September). Multi-channel u-net for music source separation. In 2020 IEEE 22nd international workshop on multimedia signal processing (MMSP) (pp. 1-6). IEEE.
71. Manilow, Ethan, Gordon Wichern, Prem Seetharaman, and Jonathan Le Roux. "Cutting music source separation some Slakh: A dataset to study the impact of training data quality and quantity." In 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), pp. 45-49. IEEE, 2019.
72. Tong, W., Zhu, J., Chen, J., Kang, S., Jiang, T., Li, Y., ... & Meng, H. (2024, April). SCNet: sparse compression network for music source separation. In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1276-1280). IEEE.
73. Virtanen, T. (2006). Sound source separation in monaural music signals. Tampere University of Technology.
74. Liutkus, A., Durrieu, J. L., Daudet, L., & Richard, G. (2013, July). An overview of informed audio source separation. In 2013 14th International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS) (pp. 1-4). IEEE.
75. Duan, Z., Zhang, Y., Zhang, C., & Shi, Z. (2008). Unsupervised single-channel music source separation by average harmonic structure modeling. IEEE Transactions on Audio, Speech, and Language Processing, 16(4), 766-778.
76. Gusó, E., Pons, J., Pascual, S., & Serrà, J. (2022, May). On loss functions and evaluation metrics for music source separation. In ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 306-310). IEEE. 
